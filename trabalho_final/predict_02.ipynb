{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1984 entries, 0 to 1983\n",
      "Columns: 4379 entries, Unnamed: 0 to y\n",
      "dtypes: float64(4377), int64(2)\n",
      "memory usage: 66.3 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dsViaturas = pd.read_csv('viaturas4Model.csv')\n",
    "dsViaturas.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4368</th>\n",
       "      <th>4369</th>\n",
       "      <th>4370</th>\n",
       "      <th>4371</th>\n",
       "      <th>4372</th>\n",
       "      <th>4373</th>\n",
       "      <th>4374</th>\n",
       "      <th>4375</th>\n",
       "      <th>4376</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>2759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>2641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>1792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 4379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    0    1    2    3    4    5    6    7         8  ...  4368  \\\n",
       "618          618  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "63            63  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1885        2759  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "778          778  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1398        1398  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.161244  ...   0.0   \n",
       "1861        2641  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "700          700  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1783        2138  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "25            25  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "218          218  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1725        1792  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "108          108  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1211        1211  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "196          196  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1475        1475  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "\n",
       "      4369  4370  4371  4372  4373  4374  4375  4376  y  \n",
       "618    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "63     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1885   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "778    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1398   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1861   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "700    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1783   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "25     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "218    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "1725   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "108    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1211   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "196    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1475   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "\n",
       "[15 rows x 4379 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsViaturas.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset dimensions: (1984, 4379)\n",
      "Dataset dimensions after drop NaN values: (1984, 4379)\n",
      "ML problem type: Classification\n",
      "   Applied metrics: ['f1', 'accuracy', 'roc_auc']\n",
      "Normalizing the variables...\n",
      "Splitting dataset...\n",
      "   X_train dimensions: (1587, 4378)\n",
      "Features engineering - Testing correlation with Y...\n",
      "   Features engineering - Features reduction after correlation test with Y: 95.20% (210 remained)\n",
      "Features engineering - Testing redudance between features...\n",
      "   Features engineering - Features reduction after redudance test: 95.27% (207 remained)\n",
      "Selected algorithms: ['KNeighborsClassifier', 'SVC', 'GaussianProcessClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'MLPClassifier', 'AdaBoostClassifier', 'GaussianNB', 'QuadraticDiscriminantAnalysis', 'XGBClassifier', 'MultinomialNB', 'LogisticRegression']\n",
      "Nº of training possible combinations: 4.9365136719637124e+63 (4.113761393303094e+62 features combinations, 12 algorithms)\n",
      "   *Model trained: f1 = 0.66833 | 207 features | KNeighborsClassifier(n_ne | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', \n",
      "   *Model trained: f1 = 0.84029 | 207 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '\n",
      "   *Model trained: f1 = 0.84382 | 207 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.68894 | 207 features | DecisionTreeClassifier(max_ | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195'\n",
      "   *Model trained: f1 = 0.14560 | 207 features | RandomForestClassifier(max_ | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195'\n",
      "   *Model trained: f1 = 0.80183 | 207 features | MLPClassifier(alph | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180',\n",
      "   *Model trained: f1 = 0.77704 | 207 features | AdaBoostClassifier() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180\n",
      "   *Model trained: f1 = 0.63614 | 207 features | GaussianNB() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169\n",
      "   *Model trained: f1 = 0.62264 | 207 features | QuadraticDiscriminantAnalysis() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4\n",
      "   *Model trained: f1 = 0.80945 | 207 features | XGBClassifier(base | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180',\n",
      "   *Model trained: f1 = 0.71348 | 207 features | MultinomialNB() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4\n",
      "   *Model trained: f1 = 0.71348 | 207 features | MultinomialNB() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4\n",
      "   *Model trained: f1 = 0.77977 | 207 features | LogisticRegression() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180\n",
      "   *Model trained: f1 = 0.83531 | 195 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '\n",
      "   *Model trained: f1 = 0.68232 | 199 features | DecisionTreeClassifier(max_ | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195'\n",
      "   *Model trained: f1 = 0.76375 | 196 features | LogisticRegression() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4195', '4180', '4169\n",
      "   *Model trained: f1 = 0.77818 | 204 features | LogisticRegression() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180\n",
      "   *Model trained: f1 = 0.83506 | 196 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4196', '4195', '4180', '4169', '4135', '\n",
      "   *Model trained: f1 = 0.83964 | 205 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '\n",
      "   *Model trained: f1 = 0.83222 | 197 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '\n",
      "   *Model trained: f1 = 0.83325 | 198 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '\n",
      "   *Model trained: f1 = 0.83510 | 198 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '\n",
      "   *Model trained: f1 = 0.67100 | 199 features | KNeighborsClassifier(n_ne | ('4275', '4274', '4255', '4253', '4251', '4218', '4196', '4195', '4180', \n",
      "   *Model trained: f1 = 0.75373 | 190 features | SVC(prob | ('4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '4135', '\n",
      "   *Model trained: f1 = 0.84096 | 192 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4195', '41\n",
      "   *Model trained: f1 = 0.84221 | 198 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83301 | 198 features | SVC(prob | ('4275', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '4135', '\n",
      "   *Model trained: f1 = 0.83840 | 203 features | SVC(prob | ('4275', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '4135', '\n",
      "   *Model trained: f1 = 0.70694 | 195 features | MultinomialNB() | ('4274', '4255', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '4029', '4\n",
      "   *Model trained: f1 = 0.70694 | 195 features | MultinomialNB() | ('4274', '4255', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '4029', '4\n",
      "   *Model trained: f1 = 0.83911 | 201 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '\n",
      "   *Model trained: f1 = 0.66263 | 184 features | DecisionTreeClassifier(max_ | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4195', '4180'\n",
      "   *Model trained: f1 = 0.84430 | 198 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83788 | 203 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '\n",
      "   *Model trained: f1 = 0.83763 | 199 features | SVC(prob | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4169', '\n",
      "   *Model trained: f1 = 0.84346 | 200 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4195', '41\n",
      "   *Model trained: f1 = 0.70801 | 194 features | MultinomialNB() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4\n",
      "   *Model trained: f1 = 0.70801 | 194 features | MultinomialNB() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '4180', '4\n",
      "   *Model trained: f1 = 0.84411 | 189 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84138 | 200 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84408 | 205 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83461 | 194 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84146 | 200 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4195', '41\n",
      "   *Model trained: f1 = 0.83896 | 199 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84297 | 200 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83866 | 199 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.82890 | 195 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84282 | 206 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84432 | 206 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84304 | 201 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84410 | 190 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83928 | 196 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.82969 | 197 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83489 | 194 features | GaussianProcessClassifier(kern | ('4275', '4255', '4253', '4251', '4223', '4218', '4196', '4195', '41\n",
      "   *Model trained: f1 = 0.68867 | 196 features | DecisionTreeClassifier(max_ | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195'\n",
      "   *Model trained: f1 = 0.68863 | 196 features | DecisionTreeClassifier(max_ | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4195'\n",
      "   *Model trained: f1 = 0.83320 | 179 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84284 | 197 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84562 | 198 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83136 | 176 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83331 | 195 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83148 | 181 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83322 | 178 features | GaussianProcessClassifier(kern | ('4274', '4251', '4218', '4196', '4195', '4180', '4169', '4135', '40\n",
      "   *Model trained: f1 = 0.84732 | 197 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84390 | 190 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84160 | 196 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4251', '4223', '4218', '4196', '4195', '41\n",
      "   *Model trained: f1 = 0.84537 | 199 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83295 | 193 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84656 | 204 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84728 | 200 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84135 | 187 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.67066 | 189 features | MultinomialNB() | ('4275', '4274', '4255', '4253', '4251', '4218', '4196', '4195', '4180', '4169', '4\n",
      "   *Model trained: f1 = 0.67066 | 189 features | MultinomialNB() | ('4275', '4274', '4255', '4253', '4251', '4218', '4196', '4195', '4180', '4169', '4\n",
      "   *Model trained: f1 = 0.83902 | 187 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.83600 | 196 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.70739 | 190 features | MultinomialNB() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4180', '4169', '4\n",
      "   *Model trained: f1 = 0.70739 | 190 features | MultinomialNB() | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '4180', '4169', '4\n",
      "   *Model trained: f1 = 0.84525 | 200 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n",
      "   *Model trained: f1 = 0.84682 | 203 features | GaussianProcessClassifier(kern | ('4275', '4274', '4255', '4253', '4251', '4223', '4218', '4196', '41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_order</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>features</th>\n",
       "      <th>n_features</th>\n",
       "      <th>train_time</th>\n",
       "      <th>mem_max</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>197</td>\n",
       "      <td>360.537774</td>\n",
       "      <td>1182.929688</td>\n",
       "      <td>0.847323</td>\n",
       "      <td>0.883062</td>\n",
       "      <td>0.939462</td>\n",
       "      <td>[[214, 24], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>200</td>\n",
       "      <td>367.145105</td>\n",
       "      <td>1182.355469</td>\n",
       "      <td>0.847279</td>\n",
       "      <td>0.882557</td>\n",
       "      <td>0.939915</td>\n",
       "      <td>[[212, 26], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>203</td>\n",
       "      <td>366.554974</td>\n",
       "      <td>1314.945312</td>\n",
       "      <td>0.846817</td>\n",
       "      <td>0.882051</td>\n",
       "      <td>0.940462</td>\n",
       "      <td>[[215, 23], [27, 132]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>204</td>\n",
       "      <td>367.882921</td>\n",
       "      <td>1117.796875</td>\n",
       "      <td>0.846565</td>\n",
       "      <td>0.882052</td>\n",
       "      <td>0.942213</td>\n",
       "      <td>[[214, 24], [28, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>198</td>\n",
       "      <td>315.770649</td>\n",
       "      <td>1119.281250</td>\n",
       "      <td>0.845617</td>\n",
       "      <td>0.881550</td>\n",
       "      <td>0.939847</td>\n",
       "      <td>[[212, 26], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=3)</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>207</td>\n",
       "      <td>3.081679</td>\n",
       "      <td>547.046875</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.785778</td>\n",
       "      <td>0.837173</td>\n",
       "      <td>[[221, 17], [69, 90]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>29</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=5)</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>184</td>\n",
       "      <td>1.249242</td>\n",
       "      <td>678.507812</td>\n",
       "      <td>0.662629</td>\n",
       "      <td>0.785778</td>\n",
       "      <td>0.744608</td>\n",
       "      <td>[[227, 11], [66, 93]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>7</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>207</td>\n",
       "      <td>2.195161</td>\n",
       "      <td>581.218750</td>\n",
       "      <td>0.636144</td>\n",
       "      <td>0.773690</td>\n",
       "      <td>0.885500</td>\n",
       "      <td>[[213, 25], [93, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>8</td>\n",
       "      <td>QuadraticDiscriminantAnalysis()</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>207</td>\n",
       "      <td>6.024277</td>\n",
       "      <td>586.656250</td>\n",
       "      <td>0.622643</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>0.885165</td>\n",
       "      <td>[[214, 24], [91, 68]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier(max_depth=5, max_featur...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>207</td>\n",
       "      <td>3.080622</td>\n",
       "      <td>602.441406</td>\n",
       "      <td>0.145597</td>\n",
       "      <td>0.628528</td>\n",
       "      <td>0.768318</td>\n",
       "      <td>[[237, 1], [153, 6]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_order                                          algorithm  \\\n",
       "0            59  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "1            65  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "2            72  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "3            64  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "4            54  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "..          ...                                                ...   \n",
       "68            0                KNeighborsClassifier(n_neighbors=3)   \n",
       "69           29                DecisionTreeClassifier(max_depth=5)   \n",
       "70            7                                       GaussianNB()   \n",
       "71            8                    QuadraticDiscriminantAnalysis()   \n",
       "72            4  RandomForestClassifier(max_depth=5, max_featur...   \n",
       "\n",
       "                                             features n_features  train_time  \\\n",
       "0   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        197  360.537774   \n",
       "1   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        200  367.145105   \n",
       "2   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        203  366.554974   \n",
       "3   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        204  367.882921   \n",
       "4   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        198  315.770649   \n",
       "..                                                ...        ...         ...   \n",
       "68  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        207    3.081679   \n",
       "69  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        184    1.249242   \n",
       "70  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        207    2.195161   \n",
       "71  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        207    6.024277   \n",
       "72  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        207    3.080622   \n",
       "\n",
       "        mem_max        f1  accuracy   roc_auc        confusion_matrix  \n",
       "0   1182.929688  0.847323  0.883062  0.939462  [[214, 24], [25, 134]]  \n",
       "1   1182.355469  0.847279  0.882557  0.939915  [[212, 26], [25, 134]]  \n",
       "2   1314.945312  0.846817  0.882051  0.940462  [[215, 23], [27, 132]]  \n",
       "3   1117.796875  0.846565  0.882052  0.942213  [[214, 24], [28, 131]]  \n",
       "4   1119.281250  0.845617  0.881550  0.939847  [[212, 26], [26, 133]]  \n",
       "..          ...       ...       ...       ...                     ...  \n",
       "68   547.046875  0.668333  0.785778  0.837173   [[221, 17], [69, 90]]  \n",
       "69   678.507812  0.662629  0.785778  0.744608   [[227, 11], [66, 93]]  \n",
       "70   581.218750  0.636144  0.773690  0.885500   [[213, 25], [93, 66]]  \n",
       "71   586.656250  0.622643  0.766127  0.885165   [[214, 24], [91, 68]]  \n",
       "72   602.441406  0.145597  0.628528  0.768318    [[237, 1], [153, 6]]  \n",
       "\n",
       "[73 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autoML import AutoML\n",
    "from multiprocessing import Pool\n",
    "\n",
    "pool = Pool(processes=10)\n",
    "automl = AutoML(dsViaturas, 'y', min_x_y_correlation_rate=0.05, pool=pool, ds_name='viaturas_MultinomialNB')\n",
    "automl.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_order</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>features</th>\n",
       "      <th>n_features</th>\n",
       "      <th>train_time</th>\n",
       "      <th>mem_max</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>197</td>\n",
       "      <td>360.537774</td>\n",
       "      <td>1182.929688</td>\n",
       "      <td>0.847323</td>\n",
       "      <td>0.883062</td>\n",
       "      <td>0.939462</td>\n",
       "      <td>[[214, 24], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>200</td>\n",
       "      <td>367.145105</td>\n",
       "      <td>1182.355469</td>\n",
       "      <td>0.847279</td>\n",
       "      <td>0.882557</td>\n",
       "      <td>0.939915</td>\n",
       "      <td>[[212, 26], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>203</td>\n",
       "      <td>366.554974</td>\n",
       "      <td>1314.945312</td>\n",
       "      <td>0.846817</td>\n",
       "      <td>0.882051</td>\n",
       "      <td>0.940462</td>\n",
       "      <td>[[215, 23], [27, 132]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>204</td>\n",
       "      <td>367.882921</td>\n",
       "      <td>1117.796875</td>\n",
       "      <td>0.846565</td>\n",
       "      <td>0.882052</td>\n",
       "      <td>0.942213</td>\n",
       "      <td>[[214, 24], [28, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>198</td>\n",
       "      <td>315.770649</td>\n",
       "      <td>1119.281250</td>\n",
       "      <td>0.845617</td>\n",
       "      <td>0.881550</td>\n",
       "      <td>0.939847</td>\n",
       "      <td>[[212, 26], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>199</td>\n",
       "      <td>366.886981</td>\n",
       "      <td>1310.046875</td>\n",
       "      <td>0.845375</td>\n",
       "      <td>0.881049</td>\n",
       "      <td>0.941444</td>\n",
       "      <td>[[212, 26], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>200</td>\n",
       "      <td>365.247030</td>\n",
       "      <td>1290.363281</td>\n",
       "      <td>0.845251</td>\n",
       "      <td>0.881049</td>\n",
       "      <td>0.941059</td>\n",
       "      <td>[[212, 26], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>206</td>\n",
       "      <td>499.788598</td>\n",
       "      <td>1096.523438</td>\n",
       "      <td>0.844321</td>\n",
       "      <td>0.880037</td>\n",
       "      <td>0.942123</td>\n",
       "      <td>[[214, 24], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>198</td>\n",
       "      <td>676.542117</td>\n",
       "      <td>1049.632812</td>\n",
       "      <td>0.844303</td>\n",
       "      <td>0.880538</td>\n",
       "      <td>0.941598</td>\n",
       "      <td>[[215, 23], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>189</td>\n",
       "      <td>641.242256</td>\n",
       "      <td>1115.148438</td>\n",
       "      <td>0.844107</td>\n",
       "      <td>0.880040</td>\n",
       "      <td>0.937998</td>\n",
       "      <td>[[212, 26], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>190</td>\n",
       "      <td>395.672120</td>\n",
       "      <td>1161.066406</td>\n",
       "      <td>0.844104</td>\n",
       "      <td>0.880041</td>\n",
       "      <td>0.937744</td>\n",
       "      <td>[[212, 26], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>205</td>\n",
       "      <td>701.190068</td>\n",
       "      <td>1093.226562</td>\n",
       "      <td>0.844076</td>\n",
       "      <td>0.880036</td>\n",
       "      <td>0.942281</td>\n",
       "      <td>[[214, 24], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>190</td>\n",
       "      <td>363.388210</td>\n",
       "      <td>1221.359375</td>\n",
       "      <td>0.843903</td>\n",
       "      <td>0.880041</td>\n",
       "      <td>0.938347</td>\n",
       "      <td>[[211, 27], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>207</td>\n",
       "      <td>896.422000</td>\n",
       "      <td>965.722656</td>\n",
       "      <td>0.843822</td>\n",
       "      <td>0.880036</td>\n",
       "      <td>0.941890</td>\n",
       "      <td>[[215, 23], [28, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>200</td>\n",
       "      <td>628.594241</td>\n",
       "      <td>985.613281</td>\n",
       "      <td>0.843458</td>\n",
       "      <td>0.880535</td>\n",
       "      <td>0.936407</td>\n",
       "      <td>[[210, 28], [28, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>201</td>\n",
       "      <td>496.027715</td>\n",
       "      <td>1115.468750</td>\n",
       "      <td>0.843039</td>\n",
       "      <td>0.879532</td>\n",
       "      <td>0.941244</td>\n",
       "      <td>[[216, 22], [28, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>41</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>200</td>\n",
       "      <td>495.179712</td>\n",
       "      <td>1199.382812</td>\n",
       "      <td>0.842966</td>\n",
       "      <td>0.879531</td>\n",
       "      <td>0.941523</td>\n",
       "      <td>[[215, 23], [27, 132]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>197</td>\n",
       "      <td>319.939849</td>\n",
       "      <td>1071.652344</td>\n",
       "      <td>0.842843</td>\n",
       "      <td>0.879033</td>\n",
       "      <td>0.941131</td>\n",
       "      <td>[[213, 25], [23, 136]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>206</td>\n",
       "      <td>494.728494</td>\n",
       "      <td>1053.113281</td>\n",
       "      <td>0.842819</td>\n",
       "      <td>0.879531</td>\n",
       "      <td>0.942054</td>\n",
       "      <td>[[214, 24], [27, 132]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>198</td>\n",
       "      <td>462.881578</td>\n",
       "      <td>1048.136719</td>\n",
       "      <td>0.842213</td>\n",
       "      <td>0.878523</td>\n",
       "      <td>0.939382</td>\n",
       "      <td>[[214, 24], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>61</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4251, 4223, 4218, 4196, 419...</td>\n",
       "      <td>196</td>\n",
       "      <td>370.886659</td>\n",
       "      <td>1287.207031</td>\n",
       "      <td>0.841603</td>\n",
       "      <td>0.878027</td>\n",
       "      <td>0.940101</td>\n",
       "      <td>[[214, 24], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>39</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>200</td>\n",
       "      <td>783.794264</td>\n",
       "      <td>1184.460938</td>\n",
       "      <td>0.841460</td>\n",
       "      <td>0.879023</td>\n",
       "      <td>0.936534</td>\n",
       "      <td>[[211, 27], [28, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>36</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>200</td>\n",
       "      <td>697.013221</td>\n",
       "      <td>1095.632812</td>\n",
       "      <td>0.841384</td>\n",
       "      <td>0.878519</td>\n",
       "      <td>0.941031</td>\n",
       "      <td>[[215, 23], [28, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>66</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>187</td>\n",
       "      <td>356.468181</td>\n",
       "      <td>1145.980469</td>\n",
       "      <td>0.841350</td>\n",
       "      <td>0.878523</td>\n",
       "      <td>0.937920</td>\n",
       "      <td>[[211, 27], [27, 132]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>GaussianProcessClassifier(kernel=1**2 * RBF(le...</td>\n",
       "      <td>(4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...</td>\n",
       "      <td>192</td>\n",
       "      <td>658.257520</td>\n",
       "      <td>1004.414062</td>\n",
       "      <td>0.840958</td>\n",
       "      <td>0.878519</td>\n",
       "      <td>0.934911</td>\n",
       "      <td>[[213, 25], [28, 131]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_order                                          algorithm  \\\n",
       "0            59  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "1            65  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "2            72  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "3            64  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "4            54  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "5            62  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "6            71  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "7            45  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "8            30  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "9            35  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "10           47  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "11           37  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "12           60  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "13            2  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "14           33  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "15           46  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "16           41  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "17           53  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "18           44  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "19           24  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "20           61  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "21           39  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "22           36  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "23           66  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "24           23  GaussianProcessClassifier(kernel=1**2 * RBF(le...   \n",
       "\n",
       "                                             features n_features  train_time  \\\n",
       "0   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        197  360.537774   \n",
       "1   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        200  367.145105   \n",
       "2   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        203  366.554974   \n",
       "3   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        204  367.882921   \n",
       "4   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        198  315.770649   \n",
       "5   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        199  366.886981   \n",
       "6   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        200  365.247030   \n",
       "7   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        206  499.788598   \n",
       "8   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        198  676.542117   \n",
       "9   (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        189  641.242256   \n",
       "10  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        190  395.672120   \n",
       "11  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        205  701.190068   \n",
       "12  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        190  363.388210   \n",
       "13  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        207  896.422000   \n",
       "14  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        200  628.594241   \n",
       "15  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        201  496.027715   \n",
       "16  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        200  495.179712   \n",
       "17  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        197  319.939849   \n",
       "18  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        206  494.728494   \n",
       "19  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        198  462.881578   \n",
       "20  (4275, 4274, 4255, 4251, 4223, 4218, 4196, 419...        196  370.886659   \n",
       "21  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        200  783.794264   \n",
       "22  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        200  697.013221   \n",
       "23  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        187  356.468181   \n",
       "24  (4275, 4274, 4255, 4253, 4251, 4223, 4218, 419...        192  658.257520   \n",
       "\n",
       "        mem_max        f1  accuracy   roc_auc        confusion_matrix  \n",
       "0   1182.929688  0.847323  0.883062  0.939462  [[214, 24], [25, 134]]  \n",
       "1   1182.355469  0.847279  0.882557  0.939915  [[212, 26], [25, 134]]  \n",
       "2   1314.945312  0.846817  0.882051  0.940462  [[215, 23], [27, 132]]  \n",
       "3   1117.796875  0.846565  0.882052  0.942213  [[214, 24], [28, 131]]  \n",
       "4   1119.281250  0.845617  0.881550  0.939847  [[212, 26], [26, 133]]  \n",
       "5   1310.046875  0.845375  0.881049  0.941444  [[212, 26], [25, 134]]  \n",
       "6   1290.363281  0.845251  0.881049  0.941059  [[212, 26], [24, 135]]  \n",
       "7   1096.523438  0.844321  0.880037  0.942123  [[214, 24], [26, 133]]  \n",
       "8   1049.632812  0.844303  0.880538  0.941598  [[215, 23], [26, 133]]  \n",
       "9   1115.148438  0.844107  0.880040  0.937998  [[212, 26], [25, 134]]  \n",
       "10  1161.066406  0.844104  0.880041  0.937744  [[212, 26], [24, 135]]  \n",
       "11  1093.226562  0.844076  0.880036  0.942281  [[214, 24], [25, 134]]  \n",
       "12  1221.359375  0.843903  0.880041  0.938347  [[211, 27], [25, 134]]  \n",
       "13   965.722656  0.843822  0.880036  0.941890  [[215, 23], [28, 131]]  \n",
       "14   985.613281  0.843458  0.880535  0.936407  [[210, 28], [28, 131]]  \n",
       "15  1115.468750  0.843039  0.879532  0.941244  [[216, 22], [28, 131]]  \n",
       "16  1199.382812  0.842966  0.879531  0.941523  [[215, 23], [27, 132]]  \n",
       "17  1071.652344  0.842843  0.879033  0.941131  [[213, 25], [23, 136]]  \n",
       "18  1053.113281  0.842819  0.879531  0.942054  [[214, 24], [27, 132]]  \n",
       "19  1048.136719  0.842213  0.878523  0.939382  [[214, 24], [26, 133]]  \n",
       "20  1287.207031  0.841603  0.878027  0.940101  [[214, 24], [24, 135]]  \n",
       "21  1184.460938  0.841460  0.879023  0.936534  [[211, 27], [28, 131]]  \n",
       "22  1095.632812  0.841384  0.878519  0.941031  [[215, 23], [28, 131]]  \n",
       "23  1145.980469  0.841350  0.878523  0.937920  [[211, 27], [27, 132]]  \n",
       "24  1004.414062  0.840958  0.878519  0.934911  [[213, 25], [28, 131]]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.getResults().head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl.getBestConfusionMatrix()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4b62fceddc06dd276b407a252c1a463ef87e47b1a1840188fdb674abd87f8b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

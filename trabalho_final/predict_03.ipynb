{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1984 entries, 0 to 1983\n",
      "Columns: 4379 entries, Unnamed: 0 to y\n",
      "dtypes: float64(4377), int64(2)\n",
      "memory usage: 66.3 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dsViaturas = pd.read_csv('viaturas4Model.csv')\n",
    "dsViaturas.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4368</th>\n",
       "      <th>4369</th>\n",
       "      <th>4370</th>\n",
       "      <th>4371</th>\n",
       "      <th>4372</th>\n",
       "      <th>4373</th>\n",
       "      <th>4374</th>\n",
       "      <th>4375</th>\n",
       "      <th>4376</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>1632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>1100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>1619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>2813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>2050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>2978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>1141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>1979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 4379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    0    1    2    3    4    5    6    7         8  ...  4368  \\\n",
       "799          799  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "356          356  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1632        1632  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "497          497  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1100        1100  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.246992  ...   0.0   \n",
       "1619        1619  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1893        2813  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1246        1246  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1765        2050  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1921        2978  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1141        1141  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1603        1603  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "493          493  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "710          710  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "1751        1979  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...   0.0   \n",
       "\n",
       "      4369  4370  4371  4372  4373  4374  4375  4376  y  \n",
       "799    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "356    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1632   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "497    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1100   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "1619   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "1893   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "1246   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "1765   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "1921   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "1141   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1603   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "493    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "710    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0  \n",
       "1751   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1  \n",
       "\n",
       "[15 rows x 4379 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsViaturas.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset dimensions: (1984, 4379)\n",
      "Dataset dimensions after drop NaN values: (1984, 4379)\n",
      "ML problem type: Classification\n",
      "   Applied metrics: ['f1', 'accuracy', 'roc_auc']\n",
      "Normalizing the variables...\n",
      "Splitting dataset...\n",
      "   X_train dimensions: (1587, 4378)\n",
      "Features engineering - Testing correlation with Y...\n",
      "   Features engineering - Features reduction after correlation test with Y: 95.32% (205 remained)\n",
      "Features engineering - Testing redudance between features...\n",
      "   Features engineering - Features reduction after redudance test: 95.41% (201 remained)\n",
      "Selected algorithms: ['KNeighborsClassifier', 'SVC', 'GaussianProcessClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'MLPClassifier', 'AdaBoostClassifier', 'GaussianNB', 'QuadraticDiscriminantAnalysis', 'XGBClassifier', 'MultinomialNB', 'GradientBoostingClassifier', 'HistGradientBoostingClassifier', 'VotingClassifier', 'StackingClassifier', 'LogisticRegression']\n",
      "Nº of training possible combinations: 1.0284403483258666e+62 (6.427752177036666e+60 features combinations, 16 algorithms)\n",
      "   *Model trained: f1 = 0.60866 | 201 features | KNeighborsClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135\n",
      "   *Model trained: f1 = 0.75948 | 201 features | SVC | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034', '4029'\n",
      "   *Model trained: f1 = 0.61560 | 201 features | GaussianProcessClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', \n",
      "   *Model trained: f1 = 0.70424 | 201 features | DecisionTreeClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '41\n",
      "   *Model trained: f1 = 0.73731 | 201 features | RandomForestClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '41\n",
      "   *Model trained: f1 = 0.73424 | 201 features | MLPClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '403\n",
      "   *Model trained: f1 = 0.72560 | 201 features | AdaBoostClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.54117 | 201 features | GaussianNB | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.54117 | 201 features | GaussianNB | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.65653 | 201 features | QuadraticDiscriminantAnalysis | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '415\n",
      "   *Model trained: f1 = 0.69480 | 201 features | XGBClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '403\n",
      "   *Model trained: f1 = 0.49272 | 201 features | MultinomialNB | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '403\n",
      "   *Model trained: f1 = 0.49272 | 201 features | MultinomialNB | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '403\n",
      "   *Model trained: f1 = 0.69323 | 201 features | GradientBoostingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155',\n",
      "   *Model trained: f1 = 0.64734 | 201 features | HistGradientBoostingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '41\n",
      "   *Model trained: f1 = 0.74914 | 201 features | VotingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '\n",
      "   *Model trained: f1 = 0.78547 | 201 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.64146 | 201 features | LogisticRegression | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.74888 | 183 features | VotingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '\n",
      "   *Model trained: f1 = 0.61513 | 180 features | SVC | ('4275', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034', '4029', '3964', '3892'\n",
      "   *Model trained: f1 = 0.75486 | 179 features | SVC | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034', '4029'\n",
      "   *Model trained: f1 = 0.74044 | 187 features | RandomForestClassifier | ('4284', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '40\n",
      "   *Model trained: f1 = 0.75820 | 187 features | VotingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '\n",
      "   *Model trained: f1 = 0.68888 | 177 features | XGBClassifier | ('4284', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4029', '396\n",
      "   *Model trained: f1 = 0.73856 | 172 features | AdaBoostClassifier | ('4284', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.75497 | 189 features | VotingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '\n",
      "   *Model trained: f1 = 0.50650 | 172 features | GaussianNB | ('4284', '4274', '4253', '4251', '4195', '4155', '4135', '4034', '4029', '3964', '3892',\n",
      "   *Model trained: f1 = 0.50650 | 172 features | GaussianNB | ('4284', '4274', '4253', '4251', '4195', '4155', '4135', '4034', '4029', '3964', '3892',\n",
      "   *Model trained: f1 = 0.74720 | 181 features | SVC | ('4284', '4274', '4253', '4251', '4195', '4169', '4163', '4135', '4029', '3964', '3902', '3892'\n",
      "   *Model trained: f1 = 0.57346 | 187 features | KNeighborsClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135\n",
      "   *Model trained: f1 = 0.57346 | 187 features | KNeighborsClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135\n",
      "   *Model trained: f1 = 0.78949 | 180 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.47124 | 182 features | MultinomialNB | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '403\n",
      "   *Model trained: f1 = 0.47124 | 182 features | MultinomialNB | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '403\n",
      "   *Model trained: f1 = 0.66769 | 175 features | LogisticRegression | ('4284', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034', '4029',\n",
      "   *Model trained: f1 = 0.74077 | 180 features | SVC | ('4284', '4275', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4029', '3964', '3902'\n",
      "   *Model trained: f1 = 0.79497 | 188 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.77798 | 193 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.76319 | 193 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.78570 | 189 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.78817 | 192 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.76722 | 183 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.79988 | 178 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.80199 | 198 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.77834 | 192 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.50756 | 178 features | MultinomialNB | ('4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034', '402\n",
      "   *Model trained: f1 = 0.50756 | 178 features | MultinomialNB | ('4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034', '402\n",
      "   *Model trained: f1 = 0.76496 | 181 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.77634 | 171 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4163', '4155', '4034', '4029',\n",
      "   *Model trained: f1 = 0.80038 | 200 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.78618 | 175 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4034',\n",
      "   *Model trained: f1 = 0.78786 | 170 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4155', '4135', '4034', '4029',\n",
      "   *Model trained: f1 = 0.60389 | 175 features | HistGradientBoostingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '41\n",
      "   *Model trained: f1 = 0.68186 | 177 features | AdaBoostClassifier | ('4284', '4275', '4274', '4251', '4195', '4169', '4163', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.78497 | 171 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4155', '4135', '4034', '4029',\n",
      "   *Model trained: f1 = 0.80448 | 166 features | StackingClassifier | ('4284', '4275', '4253', '4251', '4169', '4155', '4034', '3964', '3902', '3892',\n",
      "   *Model trained: f1 = 0.70410 | 182 features | GradientBoostingClassifier | ('4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.75795 | 175 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4034', '4029',\n",
      "   *Model trained: f1 = 0.79675 | 186 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4034',\n",
      "   *Model trained: f1 = 0.63150 | 172 features | QuadraticDiscriminantAnalysis | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '415\n",
      "   *Model trained: f1 = 0.79348 | 188 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.78815 | 197 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.80831 | 189 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.80600 | 181 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.79976 | 197 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.80209 | 193 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.73368 | 174 features | AdaBoostClassifier | ('4284', '4275', '4274', '4253', '4195', '4169', '4155', '4135', '4029', '3964',\n",
      "   *Model trained: f1 = 0.77001 | 173 features | StackingClassifier | ('4275', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034', '4029',\n",
      "   *Model trained: f1 = 0.79078 | 193 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.79736 | 183 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.79409 | 194 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.79205 | 198 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.78470 | 177 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.79603 | 192 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.80074 | 185 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.78580 | 192 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.79415 | 194 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.78813 | 192 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.79622 | 179 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.76092 | 180 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.80014 | 177 features | StackingClassifier | ('4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.78997 | 190 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.64559 | 172 features | LogisticRegression | ('4284', '4275', '4274', '4253', '4251', '4169', '4163', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.78309 | 172 features | StackingClassifier | ('4284', '4275', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.79051 | 189 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.79073 | 191 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4155', '4135', '4034',\n",
      "   *Model trained: f1 = 0.80464 | 191 features | StackingClassifier | ('4284', '4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135',\n",
      "   *Model trained: f1 = 0.78606 | 175 features | StackingClassifier | ('4275', '4274', '4253', '4251', '4195', '4169', '4163', '4155', '4135', '4029',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_order</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>features</th>\n",
       "      <th>n_features</th>\n",
       "      <th>train_time</th>\n",
       "      <th>mem_max</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>189</td>\n",
       "      <td>16.990043</td>\n",
       "      <td>2043.324219</td>\n",
       "      <td>0.808313</td>\n",
       "      <td>0.849019</td>\n",
       "      <td>0.906508</td>\n",
       "      <td>[[213, 25], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>181</td>\n",
       "      <td>16.793514</td>\n",
       "      <td>2042.812500</td>\n",
       "      <td>0.805996</td>\n",
       "      <td>0.846487</td>\n",
       "      <td>0.905249</td>\n",
       "      <td>[[208, 30], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>191</td>\n",
       "      <td>17.073346</td>\n",
       "      <td>2076.378906</td>\n",
       "      <td>0.804642</td>\n",
       "      <td>0.848924</td>\n",
       "      <td>0.906377</td>\n",
       "      <td>[[209, 29], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4253, 4251, 4169, 4155, 4034, 396...</td>\n",
       "      <td>166</td>\n",
       "      <td>17.886407</td>\n",
       "      <td>2033.027344</td>\n",
       "      <td>0.804480</td>\n",
       "      <td>0.853956</td>\n",
       "      <td>0.905531</td>\n",
       "      <td>[[210, 28], [27, 132]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...</td>\n",
       "      <td>193</td>\n",
       "      <td>16.934006</td>\n",
       "      <td>2040.230469</td>\n",
       "      <td>0.802094</td>\n",
       "      <td>0.846392</td>\n",
       "      <td>0.910880</td>\n",
       "      <td>[[210, 28], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>7</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>201</td>\n",
       "      <td>2.403691</td>\n",
       "      <td>1426.808594</td>\n",
       "      <td>0.541172</td>\n",
       "      <td>0.710095</td>\n",
       "      <td>0.742697</td>\n",
       "      <td>[[218, 20], [99, 60]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>40</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>(4275, 4274, 4253, 4251, 4195, 4169, 4163, 415...</td>\n",
       "      <td>178</td>\n",
       "      <td>1.635108</td>\n",
       "      <td>1939.867188</td>\n",
       "      <td>0.507560</td>\n",
       "      <td>0.707753</td>\n",
       "      <td>0.765740</td>\n",
       "      <td>[[217, 21], [71, 88]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>24</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>(4284, 4274, 4253, 4251, 4195, 4155, 4135, 403...</td>\n",
       "      <td>172</td>\n",
       "      <td>2.709685</td>\n",
       "      <td>1904.710938</td>\n",
       "      <td>0.506502</td>\n",
       "      <td>0.697532</td>\n",
       "      <td>0.737115</td>\n",
       "      <td>[[218, 20], [104, 55]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>201</td>\n",
       "      <td>2.285245</td>\n",
       "      <td>1437.464844</td>\n",
       "      <td>0.492723</td>\n",
       "      <td>0.697722</td>\n",
       "      <td>0.745664</td>\n",
       "      <td>[[216, 22], [70, 89]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>28</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>182</td>\n",
       "      <td>1.494001</td>\n",
       "      <td>1901.859375</td>\n",
       "      <td>0.471241</td>\n",
       "      <td>0.697753</td>\n",
       "      <td>0.725231</td>\n",
       "      <td>[[217, 21], [77, 82]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_order                                          algorithm  \\\n",
       "0            56  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "1            57  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "2            80  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "3            49  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "4            59  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "..          ...                                                ...   \n",
       "77            7                                       GaussianNB()   \n",
       "78           40                                    MultinomialNB()   \n",
       "79           24                                       GaussianNB()   \n",
       "80           10                                    MultinomialNB()   \n",
       "81           28                                    MultinomialNB()   \n",
       "\n",
       "                                             features n_features  train_time  \\\n",
       "0   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        189   16.990043   \n",
       "1   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        181   16.793514   \n",
       "2   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        191   17.073346   \n",
       "3   (4284, 4275, 4253, 4251, 4169, 4155, 4034, 396...        166   17.886407   \n",
       "4   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...        193   16.934006   \n",
       "..                                                ...        ...         ...   \n",
       "77  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        201    2.403691   \n",
       "78  (4275, 4274, 4253, 4251, 4195, 4169, 4163, 415...        178    1.635108   \n",
       "79  (4284, 4274, 4253, 4251, 4195, 4155, 4135, 403...        172    2.709685   \n",
       "80  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        201    2.285245   \n",
       "81  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        182    1.494001   \n",
       "\n",
       "        mem_max        f1  accuracy   roc_auc        confusion_matrix  \n",
       "0   2043.324219  0.808313  0.849019  0.906508  [[213, 25], [26, 133]]  \n",
       "1   2042.812500  0.805996  0.846487  0.905249  [[208, 30], [26, 133]]  \n",
       "2   2076.378906  0.804642  0.848924  0.906377  [[209, 29], [24, 135]]  \n",
       "3   2033.027344  0.804480  0.853956  0.905531  [[210, 28], [27, 132]]  \n",
       "4   2040.230469  0.802094  0.846392  0.910880  [[210, 28], [26, 133]]  \n",
       "..          ...       ...       ...       ...                     ...  \n",
       "77  1426.808594  0.541172  0.710095  0.742697   [[218, 20], [99, 60]]  \n",
       "78  1939.867188  0.507560  0.707753  0.765740   [[217, 21], [71, 88]]  \n",
       "79  1904.710938  0.506502  0.697532  0.737115  [[218, 20], [104, 55]]  \n",
       "80  1437.464844  0.492723  0.697722  0.745664   [[216, 22], [70, 89]]  \n",
       "81  1901.859375  0.471241  0.697753  0.725231   [[217, 21], [77, 82]]  \n",
       "\n",
       "[82 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autoML import AutoML\n",
    "from multiprocessing import Pool\n",
    "\n",
    "pool = Pool(processes=10)\n",
    "automl = AutoML(dsViaturas, 'y', min_x_y_correlation_rate=0.05, pool=pool, ds_name='viaturas_ensemble')\n",
    "automl.getResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_order</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>features</th>\n",
       "      <th>n_features</th>\n",
       "      <th>train_time</th>\n",
       "      <th>mem_max</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>189</td>\n",
       "      <td>16.990043</td>\n",
       "      <td>2043.324219</td>\n",
       "      <td>0.808313</td>\n",
       "      <td>0.849019</td>\n",
       "      <td>0.906508</td>\n",
       "      <td>[[213, 25], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>181</td>\n",
       "      <td>16.793514</td>\n",
       "      <td>2042.812500</td>\n",
       "      <td>0.805996</td>\n",
       "      <td>0.846487</td>\n",
       "      <td>0.905249</td>\n",
       "      <td>[[208, 30], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>191</td>\n",
       "      <td>17.073346</td>\n",
       "      <td>2076.378906</td>\n",
       "      <td>0.804642</td>\n",
       "      <td>0.848924</td>\n",
       "      <td>0.906377</td>\n",
       "      <td>[[209, 29], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4253, 4251, 4169, 4155, 4034, 396...</td>\n",
       "      <td>166</td>\n",
       "      <td>17.886407</td>\n",
       "      <td>2033.027344</td>\n",
       "      <td>0.804480</td>\n",
       "      <td>0.853956</td>\n",
       "      <td>0.905531</td>\n",
       "      <td>[[210, 28], [27, 132]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...</td>\n",
       "      <td>193</td>\n",
       "      <td>16.934006</td>\n",
       "      <td>2040.230469</td>\n",
       "      <td>0.802094</td>\n",
       "      <td>0.846392</td>\n",
       "      <td>0.910880</td>\n",
       "      <td>[[210, 28], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...</td>\n",
       "      <td>198</td>\n",
       "      <td>17.203846</td>\n",
       "      <td>2017.375000</td>\n",
       "      <td>0.801990</td>\n",
       "      <td>0.838924</td>\n",
       "      <td>0.905671</td>\n",
       "      <td>[[212, 26], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...</td>\n",
       "      <td>185</td>\n",
       "      <td>16.755638</td>\n",
       "      <td>2062.324219</td>\n",
       "      <td>0.800738</td>\n",
       "      <td>0.836456</td>\n",
       "      <td>0.908694</td>\n",
       "      <td>[[213, 25], [28, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>200</td>\n",
       "      <td>18.242252</td>\n",
       "      <td>2016.500000</td>\n",
       "      <td>0.800376</td>\n",
       "      <td>0.843892</td>\n",
       "      <td>0.905757</td>\n",
       "      <td>[[209, 29], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4275, 4274, 4253, 4251, 4195, 4169, 4163, 415...</td>\n",
       "      <td>177</td>\n",
       "      <td>16.606289</td>\n",
       "      <td>2068.839844</td>\n",
       "      <td>0.800142</td>\n",
       "      <td>0.843924</td>\n",
       "      <td>0.908842</td>\n",
       "      <td>[[214, 24], [28, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>178</td>\n",
       "      <td>17.628805</td>\n",
       "      <td>2005.585938</td>\n",
       "      <td>0.799878</td>\n",
       "      <td>0.851487</td>\n",
       "      <td>0.906442</td>\n",
       "      <td>[[213, 25], [27, 132]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>58</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>197</td>\n",
       "      <td>17.237580</td>\n",
       "      <td>2062.710938</td>\n",
       "      <td>0.799755</td>\n",
       "      <td>0.838924</td>\n",
       "      <td>0.906181</td>\n",
       "      <td>[[210, 28], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...</td>\n",
       "      <td>183</td>\n",
       "      <td>16.783662</td>\n",
       "      <td>2061.671875</td>\n",
       "      <td>0.797360</td>\n",
       "      <td>0.851582</td>\n",
       "      <td>0.905723</td>\n",
       "      <td>[[214, 24], [29, 130]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>52</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>186</td>\n",
       "      <td>18.281736</td>\n",
       "      <td>2029.328125</td>\n",
       "      <td>0.796751</td>\n",
       "      <td>0.838987</td>\n",
       "      <td>0.906932</td>\n",
       "      <td>[[210, 28], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>72</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>179</td>\n",
       "      <td>16.657469</td>\n",
       "      <td>2069.226562</td>\n",
       "      <td>0.796222</td>\n",
       "      <td>0.846456</td>\n",
       "      <td>0.906950</td>\n",
       "      <td>[[212, 26], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>67</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>192</td>\n",
       "      <td>16.932186</td>\n",
       "      <td>2054.179688</td>\n",
       "      <td>0.796026</td>\n",
       "      <td>0.841456</td>\n",
       "      <td>0.903383</td>\n",
       "      <td>[[209, 29], [23, 136]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>188</td>\n",
       "      <td>18.986386</td>\n",
       "      <td>1986.367188</td>\n",
       "      <td>0.794970</td>\n",
       "      <td>0.843956</td>\n",
       "      <td>0.896189</td>\n",
       "      <td>[[210, 28], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>70</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>194</td>\n",
       "      <td>16.867359</td>\n",
       "      <td>2072.863281</td>\n",
       "      <td>0.794153</td>\n",
       "      <td>0.833861</td>\n",
       "      <td>0.906289</td>\n",
       "      <td>[[211, 27], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>194</td>\n",
       "      <td>16.857847</td>\n",
       "      <td>2060.269531</td>\n",
       "      <td>0.794090</td>\n",
       "      <td>0.828892</td>\n",
       "      <td>0.903394</td>\n",
       "      <td>[[208, 30], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>54</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>188</td>\n",
       "      <td>16.824720</td>\n",
       "      <td>2038.890625</td>\n",
       "      <td>0.793481</td>\n",
       "      <td>0.848987</td>\n",
       "      <td>0.900499</td>\n",
       "      <td>[[209, 29], [24, 135]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>65</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>198</td>\n",
       "      <td>18.349520</td>\n",
       "      <td>2062.750000</td>\n",
       "      <td>0.792050</td>\n",
       "      <td>0.836424</td>\n",
       "      <td>0.907905</td>\n",
       "      <td>[[209, 29], [25, 134]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>62</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>193</td>\n",
       "      <td>16.932749</td>\n",
       "      <td>2059.148438</td>\n",
       "      <td>0.790778</td>\n",
       "      <td>0.836456</td>\n",
       "      <td>0.906690</td>\n",
       "      <td>[[211, 27], [26, 133]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>79</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...</td>\n",
       "      <td>191</td>\n",
       "      <td>17.091717</td>\n",
       "      <td>2067.144531</td>\n",
       "      <td>0.790735</td>\n",
       "      <td>0.838924</td>\n",
       "      <td>0.909335</td>\n",
       "      <td>[[211, 27], [23, 136]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>78</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...</td>\n",
       "      <td>189</td>\n",
       "      <td>16.971989</td>\n",
       "      <td>2075.812500</td>\n",
       "      <td>0.790512</td>\n",
       "      <td>0.843956</td>\n",
       "      <td>0.906557</td>\n",
       "      <td>[[209, 29], [23, 136]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>75</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...</td>\n",
       "      <td>190</td>\n",
       "      <td>17.241307</td>\n",
       "      <td>2064.605469</td>\n",
       "      <td>0.789972</td>\n",
       "      <td>0.838892</td>\n",
       "      <td>0.904063</td>\n",
       "      <td>[[206, 32], [23, 136]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27</td>\n",
       "      <td>StackingClassifier(estimators=[('SVC(probabili...</td>\n",
       "      <td>(4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...</td>\n",
       "      <td>180</td>\n",
       "      <td>22.105901</td>\n",
       "      <td>1973.449219</td>\n",
       "      <td>0.789489</td>\n",
       "      <td>0.831329</td>\n",
       "      <td>0.898327</td>\n",
       "      <td>[[209, 29], [26, 133]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_order                                          algorithm  \\\n",
       "0            56  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "1            57  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "2            80  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "3            49  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "4            59  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "5            38  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "6            68  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "7            43  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "8            74  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "9            37  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "10           58  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "11           63  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "12           52  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "13           72  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "14           67  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "15           31  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "16           70  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "17           64  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "18           54  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "19           65  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "20           62  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "21           79  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "22           78  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "23           75  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "24           27  StackingClassifier(estimators=[('SVC(probabili...   \n",
       "\n",
       "                                             features n_features  train_time  \\\n",
       "0   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        189   16.990043   \n",
       "1   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        181   16.793514   \n",
       "2   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        191   17.073346   \n",
       "3   (4284, 4275, 4253, 4251, 4169, 4155, 4034, 396...        166   17.886407   \n",
       "4   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...        193   16.934006   \n",
       "5   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...        198   17.203846   \n",
       "6   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...        185   16.755638   \n",
       "7   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        200   18.242252   \n",
       "8   (4275, 4274, 4253, 4251, 4195, 4169, 4163, 415...        177   16.606289   \n",
       "9   (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        178   17.628805   \n",
       "10  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        197   17.237580   \n",
       "11  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...        183   16.783662   \n",
       "12  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        186   18.281736   \n",
       "13  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        179   16.657469   \n",
       "14  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        192   16.932186   \n",
       "15  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        188   18.986386   \n",
       "16  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        194   16.867359   \n",
       "17  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        194   16.857847   \n",
       "18  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        188   16.824720   \n",
       "19  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        198   18.349520   \n",
       "20  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        193   16.932749   \n",
       "21  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...        191   17.091717   \n",
       "22  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...        189   16.971989   \n",
       "23  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 416...        190   17.241307   \n",
       "24  (4284, 4275, 4274, 4253, 4251, 4195, 4169, 415...        180   22.105901   \n",
       "\n",
       "        mem_max        f1  accuracy   roc_auc        confusion_matrix  \n",
       "0   2043.324219  0.808313  0.849019  0.906508  [[213, 25], [26, 133]]  \n",
       "1   2042.812500  0.805996  0.846487  0.905249  [[208, 30], [26, 133]]  \n",
       "2   2076.378906  0.804642  0.848924  0.906377  [[209, 29], [24, 135]]  \n",
       "3   2033.027344  0.804480  0.853956  0.905531  [[210, 28], [27, 132]]  \n",
       "4   2040.230469  0.802094  0.846392  0.910880  [[210, 28], [26, 133]]  \n",
       "5   2017.375000  0.801990  0.838924  0.905671  [[212, 26], [25, 134]]  \n",
       "6   2062.324219  0.800738  0.836456  0.908694  [[213, 25], [28, 131]]  \n",
       "7   2016.500000  0.800376  0.843892  0.905757  [[209, 29], [24, 135]]  \n",
       "8   2068.839844  0.800142  0.843924  0.908842  [[214, 24], [28, 131]]  \n",
       "9   2005.585938  0.799878  0.851487  0.906442  [[213, 25], [27, 132]]  \n",
       "10  2062.710938  0.799755  0.838924  0.906181  [[210, 28], [25, 134]]  \n",
       "11  2061.671875  0.797360  0.851582  0.905723  [[214, 24], [29, 130]]  \n",
       "12  2029.328125  0.796751  0.838987  0.906932  [[210, 28], [24, 135]]  \n",
       "13  2069.226562  0.796222  0.846456  0.906950  [[212, 26], [26, 133]]  \n",
       "14  2054.179688  0.796026  0.841456  0.903383  [[209, 29], [23, 136]]  \n",
       "15  1986.367188  0.794970  0.843956  0.896189  [[210, 28], [24, 135]]  \n",
       "16  2072.863281  0.794153  0.833861  0.906289  [[211, 27], [24, 135]]  \n",
       "17  2060.269531  0.794090  0.828892  0.903394  [[208, 30], [24, 135]]  \n",
       "18  2038.890625  0.793481  0.848987  0.900499  [[209, 29], [24, 135]]  \n",
       "19  2062.750000  0.792050  0.836424  0.907905  [[209, 29], [25, 134]]  \n",
       "20  2059.148438  0.790778  0.836456  0.906690  [[211, 27], [26, 133]]  \n",
       "21  2067.144531  0.790735  0.838924  0.909335  [[211, 27], [23, 136]]  \n",
       "22  2075.812500  0.790512  0.843956  0.906557  [[209, 29], [23, 136]]  \n",
       "23  2064.605469  0.789972  0.838892  0.904063  [[206, 32], [23, 136]]  \n",
       "24  1973.449219  0.789489  0.831329  0.898327  [[209, 29], [26, 133]]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.getResults().head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl.getBestConfusionMatrix()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4b62fceddc06dd276b407a252c1a463ef87e47b1a1840188fdb674abd87f8b3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

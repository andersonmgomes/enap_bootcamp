{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bert-lame-reviews.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1kzX1CIVE72Qky4_RZk9F0aoJF36q5vbz","authorship_tag":"ABX9TyOuVZqX478UMB6tIvlcH7EU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5BGHpbvmWF54"},"source":["# Bidirectional Encoder Representations from Transformers (BERT)\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"vxceynr1r2Cn","executionInfo":{"status":"ok","timestamp":1638735782093,"user_tz":180,"elapsed":4568,"user":{"displayName":"Fernando Sola Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk4sywxl-9dZpfH7JlYeOMEHiSGovNv-AtHwmBv5Y=s64","userId":"07411434982593234995"}}},"source":["!pip -q install transformers"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"oySg-LA1rjsx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638735789957,"user_tz":180,"elapsed":7867,"user":{"displayName":"Fernando Sola Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk4sywxl-9dZpfH7JlYeOMEHiSGovNv-AtHwmBv5Y=s64","userId":"07411434982593234995"}},"outputId":"fe442d81-b133-4229-c9b5-fe3c83298e6c"},"source":["import torch\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","import re\n","from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch.nn.functional as F\n","\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import transformers\n","from transformers import RobertaTokenizer, BertTokenizer, RobertaModel, BertModel, AdamW\n","from transformers import get_linear_schedule_with_warmup\n","import time\n","from sklearn.metrics import roc_auc_score, classification_report, plot_confusion_matrix, confusion_matrix\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import tqdm\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","\n","BERT_MODEL_NAME = 'neuralmind/bert-base-portuguese-cased'\n","# BERT_MODEL_NAME = 'neuralmind/bert-large-portuguese-cased'\n","\n","\n","class BertClassificationModel(nn.Module):\n","    def __init__(self):\n","        super(BertClassificationModel, self).__init__()\n","        self.bert_path = BERT_MODEL_NAME\n","        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n","        self.bert_drop=nn.Dropout(0.3)\n","        self.out = nn.Linear(768, 2)\n","        # self.out = nn.Linear(1024, 2)\n","\n","    def forward(self, ids, mask):\n","        outputs = self.bert(input_ids=ids, attention_mask=mask)\n","        rh=self.bert_drop(outputs.pooler_output)\n","        return self.out(rh)\n","\n","\n","class CudaDevice:\n","    def get_device(self, force_cpu=False):\n","        if not force_cpu and torch.cuda.is_available():\n","            device = torch.device(\"cuda\")\n","            print('Existe(m) %d GPU(s) disponíveis.' %\n","                  torch.cuda.device_count())\n","            print('A GPU', torch.cuda.get_device_name(0), 'será usada.')\n","        else:\n","            print('No GPU available, using the CPU instead.')\n","            device = torch.device(\"cpu\")\n","        return device\n","\n","\n","class BertDataset(Dataset):\n","\n","    def __init__(self,\n","                 data,\n","                 tokenizer,\n","                 max_len=None,\n","                 max_size_dataset=None,\n","                 ):\n","        self.tokenizer = tokenizer\n","        self.data_raw = data\n","        self.max_len = max_len\n","        self.max_size_dataset = max_size_dataset\n","        self.data, self.label = self.process_data()\n","        \n","\n","    def process_data(self):\n","        \n","        print('Carregando os dados do dataset')\n","        df = self.data_raw.copy()\n","\n","        if self.max_len:\n","            print(f'Limitando textos em {self.max_len} caracteres!')\n","            df['text'] = df['text'].apply(lambda x: x[:self.max_len] if len(x) > self.max_len else x)\n","\n","        train = df.copy()\n","\n","        if(self.max_size_dataset):\n","            print(f'Limitando dataset em {self.max_size_dataset} registros!')\n","            train = train.loc[0:self.max_size_dataset, :]\n","            \n","        train = train.reindex(np.random.permutation(train.index))\n","        train['text'] = train['text'].apply(self.clean_txt)\n","        return train['text'].values, train['label'].values\n","\n","    def clean_txt(self, text):\n","        # text = re.sub(\"'\", \"\", text)\n","        # text = re.sub(\"(\\\\W)+\", \" \", text)\n","        return text\n","\n","    def __getitem__(self, idx):\n","\n","        text = str(self.data[idx])\n","        target = int(self.label[idx])\n","\n","        data = self.tokenizer.encode_plus(\n","            text,\n","            max_length=512,\n","            pad_to_max_length=True,\n","            add_special_tokens=True,\n","            return_attention_mask=True,\n","            return_token_type_ids=False,\n","            return_overflowing_tokens=False,\n","            truncation=True,\n","            return_tensors='pt')\n","\n","        return({\n","            'ids': data['input_ids'].long(),\n","            'mask': data['attention_mask'].int(),\n","            'targets': torch.tensor([target], dtype=torch.int),\n","            'texto': text.strip(),\n","        })\n","\n","    def __len__(self):\n","        \n","        \"\"\" Return data length \"\"\"\n","        return self.label.shape[0]\n","\n","\n","def my_collate1(batches):\n","    return [{key: value for key, value in batch.items()} for batch in batches]\n","\n","\n","def loss_fun(outputs, targets):\n","    loss = nn.CrossEntropyLoss()\n","    return loss(outputs, targets)\n","\n","\n","def evaluate(target, predicted):\n","    \n","    true_label_mask = [1 if (np.argmax(x)-target[i]) ==\n","                       0 else 0 for i, x in enumerate(predicted)]\n","    nb_prediction = len(true_label_mask)\n","    true_prediction = sum(true_label_mask)\n","    false_prediction = nb_prediction-true_prediction\n","    accuracy = true_prediction/nb_prediction\n","    \n","    roc = roc_auc_score(target, predicted[:, 1])\n","    \n","    return{\n","        \"accuracy\": accuracy,\n","        \"nb exemple\": len(target),\n","        \"true_prediction\": true_prediction,\n","        \"false_prediction\": false_prediction,\n","        \"roc_auc\": roc\n","    }\n","\n","\n","def train_loop(data_loader, model, optimizer, device, scheduler=None):\n","    model.train()\n","    t0 = time.time()\n","    losses = []\n","    for batch_idx, batch in enumerate(data_loader):\n","        ids = [data[\"ids\"] for data in batch]\n","        mask = [data[\"mask\"] for data in batch]\n","        targets = [data[\"targets\"] for data in batch]\n","\n","        ids = torch.cat(ids)\n","        mask = torch.cat(mask)\n","        targets = torch.cat(targets)\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        targets = targets.to(device, dtype=torch.long)\n","\n","        optimizer.zero_grad()\n","        outputs = model(ids=ids, mask=mask)\n","        loss = loss_fun(outputs, targets)\n","        loss.backward()\n","        model.float()\n","        optimizer.step()\n","        if scheduler:\n","            scheduler.step()\n","        losses.append(loss.item())\n","        if batch_idx % 100 == 0:\n","            print(f\"___ batch index = {batch_idx} / {len(data_loader)} ({100*batch_idx / len(data_loader):.2f}%), loss = {np.mean(losses[-10:]):.4f}, time = {time.time()-t0:.2f} seconds ___\")\n","            t0 = time.time()\n","    return losses    \n","\n","\n","def eval_loop(data_loader, model, device):\n","    model.eval()\n","    fin_targets = []\n","    fin_outputs = []\n","    losses = []\n","\n","    for batch_idx, batch in tqdm.tqdm(enumerate(data_loader)):\n","        ids = [data[\"ids\"] for data in batch]\n","        mask = [data[\"mask\"] for data in batch]\n","        targets = [data[\"targets\"] for data in batch]\n","\n","        ids = torch.cat(ids)\n","        mask = torch.cat(mask)\n","        targets = torch.cat(targets)\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        targets = targets.to(device, dtype=torch.long)\n","\n","        with torch.no_grad():\n","            outputs = model(ids=ids, mask=mask)\n","            loss = loss_fun(outputs, targets)\n","            losses.append(loss.item())\n","\n","        fin_targets.append(targets.cpu().detach().numpy())\n","        fin_outputs.append(torch.softmax(outputs, dim=1).cpu().detach().numpy())\n","\n","    return np.concatenate(fin_outputs), np.concatenate(fin_targets), losses    \n","\n","########################################################################################\n","# variáveis globais\n","########################################################################################\n","device = CudaDevice().get_device(force_cpu=False)\n","\n","TRAIN_BATCH_SIZE = 4\n","EPOCH = 3\n","validation_split = .2\n","shuffle_dataset = True\n","random_seed = 42\n","MAX_LEN = None\n","MAX_SIZE_DATASET = None\n","\n","\n","########################################################################################\n","# dataset\n","########################################################################################\n","train_raw = pd.read_csv('https://docs.google.com/uc?export=download&id=1_EKfnjomkWks4VqTMIpcEIb6nB5P0Xz2')\n","train_raw.columns = ['label','text']\n","train_raw['label'] = train_raw['label'].apply(lambda x: 1 if x == 'positivo' else 0)\n","\n","\n","########################################################################################\n","# se quiser trabalhar com amostra menor\n","########################################################################################\n","SAMPLE_SIZE = 1000\n","s_labels = train_raw['label'].value_counts(normalize=True).sort_index()\n","train_raw = pd.concat([\n","    train_raw[train_raw['label']==0].sample(int(SAMPLE_SIZE * s_labels[0]), random_state=random_seed), # ~0.427427\n","    train_raw[train_raw['label']==1].sample(int(SAMPLE_SIZE * s_labels[1]), random_state=random_seed), # ~0.572573\n","])"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Existe(m) 1 GPU(s) disponíveis.\n","A GPU Tesla P100-PCIE-16GB será usada.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vt06GoqmK3B7","executionInfo":{"status":"ok","timestamp":1638735915500,"user_tz":180,"elapsed":125549,"user":{"displayName":"Fernando Sola Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk4sywxl-9dZpfH7JlYeOMEHiSGovNv-AtHwmBv5Y=s64","userId":"07411434982593234995"}},"outputId":"e6614002-7915-40cc-c21b-49d507478f7b"},"source":["print('Loading BERT tokenizer...')\n","\n","tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    train_raw[['text']], \n","    train_raw.label, \n","    test_size=0.3, \n","    stratify=train_raw.label,\n","    random_state=random_seed\n",")\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train[['text']], \n","    y_train, \n","    test_size=0.2, \n","    stratify=y_train,\n","    random_state=random_seed\n",")\n","\n","train_dataset = BertDataset(\n","    data=pd.concat([X_train, y_train], axis=1),\n","    tokenizer=tokenizer,\n","    max_len=MAX_LEN,\n","    max_size_dataset=MAX_SIZE_DATASET,\n",")\n","\n","val_dataset = BertDataset(\n","    data=pd.concat([X_val, y_val], axis=1),\n","    tokenizer=tokenizer,\n","    max_len=MAX_LEN,\n","    max_size_dataset=MAX_SIZE_DATASET,\n",")\n","\n","test_dataset = BertDataset(\n","    data=pd.concat([X_test, y_test], axis=1),\n","    tokenizer=tokenizer,\n","    max_len=MAX_LEN,\n","    max_size_dataset=MAX_SIZE_DATASET,\n",")\n","\n","train_data_loader = DataLoader(\n","  train_dataset,\n","  batch_size=TRAIN_BATCH_SIZE,\n","  collate_fn=my_collate1\n",")\n","\n","valid_data_loader = DataLoader(\n","  val_dataset,\n","  batch_size=TRAIN_BATCH_SIZE,\n","  collate_fn=my_collate1\n",")\n","\n","test_data_loader = DataLoader(\n","  test_dataset,\n","  batch_size=TRAIN_BATCH_SIZE,\n","  collate_fn=my_collate1\n",")\n","\n","lr=3e-5\n","num_training_steps=int(len(train_dataset) / TRAIN_BATCH_SIZE * EPOCH)\n","\n","model=BertClassificationModel().to(device)\n","optimizer=AdamW(model.parameters(), lr=lr)\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                        num_warmup_steps = 0,\n","                                        num_training_steps = num_training_steps)\n","val_losses=[]\n","batches_losses=[]\n","val_acc=[]\n","batches_probs=[]\n","\n","for epoch in range(EPOCH):\n","    t0 = time.time()    \n","    print(f\"\\n=============== EPOCH {epoch+1} / {EPOCH} ===============\\n\")\n","    batches_losses_tmp=train_loop(train_data_loader, model, optimizer, device)\n","    epoch_loss=np.mean(batches_losses_tmp)\n","    print(f\"\\n*** avg_loss : {epoch_loss:.2f}, time : ~{(time.time()-t0)//60} min ({time.time()-t0:.2f} sec) ***\\n\")\n","    t1=time.time()\n","    output, target, val_losses_tmp = eval_loop(valid_data_loader, model, device)\n","    print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {time.time()-t1:.2f} sec\\n\")\n","    tmp_evaluate=evaluate(target.reshape(-1), output)\n","    print(f\"=====>\\t{tmp_evaluate}\")\n","    val_acc.append(tmp_evaluate['accuracy'])\n","    val_losses.append(np.mean(val_losses_tmp))\n","    batches_losses.append(np.mean(batches_losses_tmp))\n","    batches_probs.append(output)\n","    torch.save(model, f\"drive/MyDrive/Modelos/model_epoch_{epoch+1}.pt\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n","Carregando os dados do dataset\n","Carregando os dados do dataset\n","Carregando os dados do dataset\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["\n","=============== EPOCH 1 / 3 ===============\n","\n","___ batch index = 0 / 140 (0.00%), loss = 0.7014, time = 0.27 seconds ___\n","___ batch index = 100 / 140 (71.43%), loss = 0.1914, time = 24.39 seconds ___\n","\n","*** avg_loss : 0.27, time : ~0.0 min (34.14 sec) ***\n","\n"]},{"output_type":"stream","name":"stderr","text":["35it [00:02, 11.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["==> evaluation : avg_loss = 0.15, time : 2.94 sec\n","\n","=====>\t{'accuracy': 0.9571428571428572, 'nb exemple': 140, 'true_prediction': 134, 'false_prediction': 6, 'roc_auc': 0.9837499999999999}\n","\n","=============== EPOCH 2 / 3 ===============\n","\n","___ batch index = 0 / 140 (0.00%), loss = 0.0186, time = 0.25 seconds ___\n","___ batch index = 100 / 140 (71.43%), loss = 0.0092, time = 24.45 seconds ___\n","\n","*** avg_loss : 0.06, time : ~0.0 min (34.19 sec) ***\n","\n"]},{"output_type":"stream","name":"stderr","text":["35it [00:02, 12.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["==> evaluation : avg_loss = 0.50, time : 2.93 sec\n","\n","=====>\t{'accuracy': 0.8928571428571429, 'nb exemple': 140, 'true_prediction': 125, 'false_prediction': 15, 'roc_auc': 0.9739583333333334}\n","\n","=============== EPOCH 3 / 3 ===============\n","\n","___ batch index = 0 / 140 (0.00%), loss = 0.0042, time = 0.26 seconds ___\n","___ batch index = 100 / 140 (71.43%), loss = 0.0251, time = 24.47 seconds ___\n","\n","*** avg_loss : 0.06, time : ~0.0 min (34.20 sec) ***\n","\n"]},{"output_type":"stream","name":"stderr","text":["35it [00:02, 11.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["==> evaluation : avg_loss = 0.23, time : 2.93 sec\n","\n","=====>\t{'accuracy': 0.9428571428571428, 'nb exemple': 140, 'true_prediction': 132, 'false_prediction': 8, 'roc_auc': 0.9808333333333333}\n"]}]},{"cell_type":"code","metadata":{"id":"9eFzuq2WwdcH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638735922346,"user_tz":180,"elapsed":6850,"user":{"displayName":"Fernando Sola Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk4sywxl-9dZpfH7JlYeOMEHiSGovNv-AtHwmBv5Y=s64","userId":"07411434982593234995"}},"outputId":"0938786d-f0ca-42ec-bf93-393a97eeb6f4"},"source":["model = torch.load(\"drive/MyDrive/Modelos/model_epoch_1.pt\")\n","output, target, val_losses_tmp = eval_loop(test_data_loader, model, device)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["75it [00:06, 11.90it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"Td6Wihb8_050","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638735922346,"user_tz":180,"elapsed":19,"user":{"displayName":"Fernando Sola Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk4sywxl-9dZpfH7JlYeOMEHiSGovNv-AtHwmBv5Y=s64","userId":"07411434982593234995"}},"outputId":"0ae66048-ba60-4737-886c-1f33f873116f"},"source":["print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f} sec\\n\")\n","tmp_evaluate=evaluate(target.reshape(-1), output)\n","print(f\"=====>\\t{tmp_evaluate}\")"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["==> evaluation : avg_loss = 0.18 sec\n","\n","=====>\t{'accuracy': 0.9433333333333334, 'nb exemple': 300, 'true_prediction': 283, 'false_prediction': 17, 'roc_auc': 0.9810592296511629}\n"]}]},{"cell_type":"code","metadata":{"id":"YMKZswjL6Wmq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638735923342,"user_tz":180,"elapsed":1012,"user":{"displayName":"Fernando Sola Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk4sywxl-9dZpfH7JlYeOMEHiSGovNv-AtHwmBv5Y=s64","userId":"07411434982593234995"}},"outputId":"442209ce-80ba-4629-b523-b32abfdd3017"},"source":["o = [1 if ot > .5 else 0 for ot in output[:, 1]]\n","print(classification_report(target, o))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.92      0.95      0.93       128\n","           1       0.96      0.94      0.95       172\n","\n","    accuracy                           0.94       300\n","   macro avg       0.94      0.94      0.94       300\n","weighted avg       0.94      0.94      0.94       300\n","\n"]}]},{"cell_type":"code","metadata":{"id":"jItrmujiUMdM","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1638735923344,"user_tz":180,"elapsed":9,"user":{"displayName":"Fernando Sola Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk4sywxl-9dZpfH7JlYeOMEHiSGovNv-AtHwmBv5Y=s64","userId":"07411434982593234995"}},"outputId":"65c2e64a-0341-4f52-8d2e-3142fffc0ffe"},"source":["cm = confusion_matrix(normalize='true', y_pred=o, y_true=target)\n","sns.heatmap(cm, annot=True)\n","plt.show()"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"-56v3roxdWrx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638735926876,"user_tz":180,"elapsed":3539,"user":{"displayName":"Fernando Sola Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk4sywxl-9dZpfH7JlYeOMEHiSGovNv-AtHwmBv5Y=s64","userId":"07411434982593234995"}},"outputId":"5b89e943-4be5-45f5-91a7-36d4792f833b"},"source":["device = CudaDevice().get_device(force_cpu=False)\n","\n","tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n","model = torch.load(\"drive/MyDrive/Modelos/model_epoch_1.pt\")\n","# Verifica a probabilidade da predição\n","# novo_texto = 'A entrega foi no prazo, as americanas estão de parabéns. A smart tv é muito boa, a navegação na internete e pelos aplicativos e excelente, não trava, sem falar da imagem que é de surpreender. recomendo.'\n","# novo_texto = 'não recomendo'\n","# novo_texto = 'péssima qualidade'\n","# novo_texto = 'não cumpre o que promete'\n","# novo_texto = 'tecido ruim'\n","# novo_texto = 'O produto é interessante mas não parece atender as minhas necessidades.'\n","# novo_texto = 'me arrependi'\n","# novo_texto = 'qualidade duvidosa'\n","# novo_texto = 'Não vi produto que atende tanto a minha necessidade.'\n","# novo_texto = 'Não vi produto que atende tão bem a minha necessidade.'\n","# novo_texto = 'Não encontrei problemas.'\n","# novo_texto = 'Não há reclamação.'\n","novo_texto = 'Não vi outro produto que atende tão bem a minha necessidade.'\n","# novo_texto = 'Nada demais.'\n","# novo_texto = 'péssimo atendimento.'\n","# novo_texto = '''\n","# Comprado de presente, decepcionado com a qualidade das tintas que recebeu o nome de Pentel, ficaria bem para uma criança\n","# mas não adianta para pintores mais sérios. O produto do vendedor chegou rapidamente bem embalado\n","# '''\n","# novo_texto = 'Produto chegou fora do prazo.'\n","\n","model.eval()\n","with torch.no_grad():\n","  data = tokenizer.encode_plus(\n","    novo_texto,\n","    max_length=512,\n","    pad_to_max_length=True,\n","    add_special_tokens=True,\n","    return_attention_mask=True,\n","    return_token_type_ids=False,\n","    return_overflowing_tokens=False,\n","    truncation=True,\n","    return_tensors='pt')\n","  \n","  ids = data['input_ids'].to(device, dtype=torch.long)\n","  mask = data['attention_mask'].to(device, dtype=torch.long)\n","\n","  otps = model(ids=ids, mask=mask)\n","  pred_proba = torch.softmax(otps, dim=1)\n","\n","print(f'Predição = Neg({pred_proba[0][0]:0.4f}), Pos({pred_proba[0][1]:0.4f})')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Existe(m) 1 GPU(s) disponíveis.\n","A GPU Tesla P100-PCIE-16GB será usada.\n","Predição = Neg(0.2386), Pos(0.7614)\n"]}]},{"cell_type":"code","metadata":{"id":"VZnfEZYnhXzi","executionInfo":{"status":"ok","timestamp":1638735926877,"user_tz":180,"elapsed":6,"user":{"displayName":"Fernando Sola Pereira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk4sywxl-9dZpfH7JlYeOMEHiSGovNv-AtHwmBv5Y=s64","userId":"07411434982593234995"}}},"source":[""],"execution_count":8,"outputs":[]}]}